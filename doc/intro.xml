<chapter id="ch-intro">
  <title>Introduction</title>
  
  <para>
    This chapter is intended to describe the current state and find out
    the problems which are needed to solve. 
  </para>
  
  <!-- ========================================================= -->
  <sect1>
    <title>Speech Synthesizers</title>
    
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Hardware devices</title>
      
      <para>
	Hardware synthesizers are the devices, which may be connected to PC.
	Mostly they are external, connected via serial or parallel port.  There
	are also some internal devices for ISA bus or USB.  Application may
	send textual data to the port and the device converts it to spoken
	letters and words.  Data may contain also several control sequences in
	the form of escaped characters as commands.  The problem, we are
	facing, is that each of these devices uses its own communication
	protocol.
      </para>
      
    </sect2>
   
    <!-- ********************************************************* -->
    <sect2>
      <title>Software devices</title>

      <sect3><title>Festival</title>
	<para>
	  ...
	</para>
      </sect3>

      <sect3><title>Epos</title>
	<para>
	  Epos is czech GPL synthesis ...
	</para>
      </sect3>

      <sect3><title>IBM ViaVoice</title>
	<para>
	  IBM ViaVoice is a commercial product, but we see it to be very good.
	  It is available for Linux, ....
	</para>
      </sect3>
      
      <sect3><title>MBrola project</title>
	<para>
	  MBrola is a software speech synhesis ...
	</para>
      </sect3>
      
      <sect3><title>Odmluva</title>
	<para>
	  Odmluva is a simple (and very light) czech software speech synhesis
	  ...
	</para>
      </sect3>

    </sect2>
  </sect1>
  
  <!-- ========================================================= -->
  
  <sect1>
    <title>Speaking Applications</title>
    
    <para>
    </para>
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Speakup</title>
      <para>
	
      </para>
    </sect2>

    <!-- ********************************************************* -->
    <sect2>
      <title>EmacSpeak</title>
      
      <para>
        The EmacSpeak by T. V. Raman &lt;raman@cs.cornell.edu> software package
	provides speech output for Emacs, and includes "speech servers" for
	the DECtalk speech synthesizers.
      </para>
      
      <para>
        The package emacspeak-ss provides servers for several additional synthesizers:
      </para>
      
      <itemizedlist mark="opencircle">
	<listitem><para>DoubleTalk PC and AT from <ulink url="http://www.rcsys.com/">R. C. Systems</ulink></para></listitem>
	<listitem><para>Braille 'n Speak, Type 'n Speak, and Braille Lite from <ulink url="http://www.blazie.com">Blazie Engineering</ulink></para></listitem>
	<listitem><para>Accent SA</para></listitem>
	<listitem><para>Apollo 2, JUNO, and JUNO-sp from Dolphin.</para></listitem>
	<listitem><para>Spanish ciber 232</para></listitem>
	<listitem><para>Spanish ciber 232 Plus</para></listitem>
	<listitem><para>Spanish PC Hablado notebook</para></listitem>
      </itemizedlist>
      
      <para>
        None of these programs are normally run by the user directly.  Instead,
	they are run by Emacs. That is: Emacs runs the emacspeak code, which executes
	Tcl, which interprets the server code. This approach is too closely "wired"
	to usage with Emacspeak, so it may not be used for our general purposes.
      </para>
      
      <para>
        This does not mean, that these servers are compleetly a bad idea and we
	can not use them. Thanks to the author  <ulink url="mailto:jrv@vanzandt.mv.com">Jim Van Zandt</ulink>), we can learn from
	the sources and write the output driver modules for Speech Daemon (emacspeek-ss is
	GPL).
      </para>
      
      <para>
        Bart Bunting is working on a speech server using the MBrola speech synthesis.
      </para>
      
    </sect2>
    
    <!-- ********************************************************* -->
    <!--sect2>
      <title>Bash</title>
      
      <para>
      </para>
      
    </sect2-->
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Graphical X11 applications</title>

      <para>
        The problem of speaking X Window applications can be devided
	into several subproblems. 
	
	<itemizedlist>
	  <listitem>
	    <para>Window managers</para>
	  </listitem>
	  <listitem>
	    <para>Desktop managers</para>
	  </listitem>
	  <listitem>
	    <para>Widget toolkit libraries</para>
	  </listitem>
	  <listitem>
	    <para>Applications themselves</para>
	  </listitem>
	</itemizedlist>
      </para>

      <sect3>
	<title>Window managers</title>
	<para> 
	</para>
      </sect3>
      <sect3>
	<title>Desktop managers</title>
	<para> 
	</para>
      </sect3>
      <sect3>
	<title>Widget toolkit libraries</title>
	<para>
	  Several windowing toolkit libraries take speech support 
	  into a focus the last few years. These are:
	  
	  <itemizedlist>
	    <listitem>
	      <para>GTK+ (Gnome Accessibility project)</para>
	    </listitem>
	    <listitem>
	      <para>wxWindows</para>
	    </listitem>
	    <listitem>
	      <para>Java AWT</para>
	    </listitem>
	    <listitem>
	      <para>FOX toolkit</para>
	    </listitem>
	  </itemizedlist>

	  We hope to be able to integrate Speech Daemon into these projects
	  in the future.
	  
	</para>
      </sect3>
      <sect3>
	<title>Applications themselves</title>
	<para> 
	</para>
      </sect3>

    </sect2>
    
  </sect1>

  <sect1>
    <title>What we lack</title>
    <para> 
    </para>
  </sect1>
  
</chapter>
