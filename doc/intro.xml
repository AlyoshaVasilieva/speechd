<chapter id="ch-intro">
  <title>Introduction</title>
  
  <para>
    This chapter is intended to describe the current state and find out
    the problems which are needed to solve. 
  </para>
  
  <!-- ========================================================= -->
  <sect1>
    <title>Speech Synthesizers</title>
    
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Hardware devices</title>
      
      <para>
	Hardware synthesizers are the devices, which may be connected to PC.
	Mostly they are external, connected via serial or parallel port.  There
	are also some internal devices for ISA bus or USB.  Application may
	send textual data to the port and the device converts it to spoken
	letters and words.  Data may contain also several control sequences in
	the form of escaped characters as commands.  The problem, we are
	facing, is that each of these devices uses its own communication
	protocol.
      </para>
      
    </sect2>
   
    <!-- ********************************************************* -->
    <sect2>
      <title>Software devices</title>

      <sect3><title>Festival</title>
	<para>
	  Festival is a multilingual Free Software texto to speech synthetiser
          with available high quality speech databases. One of it's problems
          is that some of the most important databases are not free.
          (eg. the database for British English is non-free). Other problem
          is that Festival is intended rather as a platform for research
          and developement than as an end-user product and therefore is
          big and not-so-easy to install. The problem we face as Speech
          Developers is that we don't know how to communicate with it
          effectivelly. (We will discuss this issue with Alan Black,
          the main developer.)
	</para>
      </sect3>

      <sect3><title>Flite</title>
	<para>
         Flite is a light fully free english speech software synthetiser
         with good quality of sound developed by the authors of festival
         as an end-user product. It's very fast, however, we currently
         don't know how to configure it (it seems it is not possible yet).
	</para>
      </sect3>

      <sect3><title>Epos</title>
	<para>
	  Epos is czech GPL synthesis.  It is an academical project and it
	  already gives quite good results.
	</para>
      </sect3>

      <sect3 id="synth_viavoice"><title>IBM ViaVoice</title>
	<para>
	  IBM ViaVoice is a commercial proprietary product, but we see
          it to be very good technically. It is available for GNU/Linux, ....
          The main problem is that ViaVoice is not free (as in freedom,
          it doesn't have to be free as gratis). Until it changes it's
          licence, we can't use it in Free World / Free Operating System.
	</para>
      </sect3>
      
      <sect3><title>MBROLA project</title>
	<para>
	  MBROLA is a software speech synhesis ... which is only partially
          free. See <xref linkend="synth_viavoice"/> for description of
          problems we face.
	</para>
      </sect3>
      
      <sect3><title>Odmluva</title>
	<para>
	  Odmluva is a simple (and very light) free czech software speech
          synhesis ...
	</para>
      </sect3>

    </sect2>
  </sect1>
  
  <!-- ========================================================= -->
  
  <sect1>
    <title>Speaking Applications</title>
    
    <para>
    </para>
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Speakup</title>
      <para>
	
      </para>
    </sect2>

    <!-- ********************************************************* -->
    <sect2>
      <title>EmacSpeak</title>
      
      <para>
        The EmacSpeak by T. V. Raman &lt;raman@cs.cornell.edu> software package
	provides speech output for Emacs, and includes "speech servers" for
	the DECtalk speech synthesizers.
      </para>
      
      <para>
        The package emacspeak-ss provides servers for several additional synthesizers:
      </para>
      
      <itemizedlist mark="opencircle">
	<listitem><para>DoubleTalk PC and AT from <ulink url="http://www.rcsys.com/">R. C. Systems</ulink></para></listitem>
	<listitem><para>Braille 'n Speak, Type 'n Speak, and Braille Lite from <ulink url="http://www.blazie.com">Blazie Engineering</ulink></para></listitem>
	<listitem><para>Accent SA</para></listitem>
	<listitem><para>Apollo 2, JUNO, and JUNO-sp from Dolphin.</para></listitem>
	<listitem><para>Spanish ciber 232</para></listitem>
	<listitem><para>Spanish ciber 232 Plus</para></listitem>
	<listitem><para>Spanish PC Hablado notebook</para></listitem>
      </itemizedlist>
      
      <para>
        None of these programs are normally run by the user directly.  Instead,
	they are run by Emacs. That is: Emacs runs the emacspeak code, which executes
	Tcl, which interprets the server code. This approach is too closely "wired"
	to usage with Emacspeak, so it can't be used for our general purposes.
      </para>
      
      <para>
        This does not mean, that these servers are compleetly a bad idea and we
	can not use them. Thanks to the author <ulink
	url="mailto:jrv@vanzandt.mv.com">Jim Van Zandt</ulink>), we can learn
	from the sources and write the output driver modules for Speech Daemon
	(emacspeek-ss is GPL).
      </para>
      
      <para>
        Bart Bunting is working on a speech server using the MBROLA speech synthesis.
      </para>
      
    </sect2>
    
    <!-- ********************************************************* -->
    <!--sect2>
      <title>Bash</title>
      
      <para>
      </para>
      
    </sect2-->
    
    <!-- ********************************************************* -->
    <sect2>
      <title>Graphical X11 applications</title>

      <para>
        The problem of speaking X Window applications can be devided
	into several subproblems. 
	
	<itemizedlist>
	  <listitem>
	    <para>Window managers</para>
	  </listitem>
	  <listitem>
	    <para>Desktop managers</para>
	  </listitem>
	  <listitem>
	    <para>Widget toolkit libraries</para>
	  </listitem>
	  <listitem>
	    <para>Applications themselves</para>
	  </listitem>
	</itemizedlist>
      </para>

      <sect3>
	<title>Window managers</title>
	<para> 
	</para>
      </sect3>
      <sect3>
	<title>Desktop managers</title>
	<para> 
	</para>
      </sect3>
      <sect3>
	<title>Widget toolkit libraries</title>
	<para>
	  Several windowing toolkit libraries take speech support 
	  into a focus the last few years. These are:
	  
	  <itemizedlist>
	    <listitem>
	      <para>GTK+ (Gnome Accessibility project)</para>
	    </listitem>
	    <listitem>
	      <para>wxWindows</para>
	    </listitem>
	    <listitem>
	      <para>Java AWT</para>
	    </listitem>
	    <listitem>
	      <para>FOX toolkit</para>
	    </listitem>
	  </itemizedlist>

	  We hope to be able to integrate Speech Daemon into these projects
	  in the future.
	  
	</para>
      </sect3>
      <sect3>
	<title>Applications themselves</title>
	<para> 
	</para>
      </sect3>

    </sect2>
    
  </sect1>

  <sect1>
    <title>What we lack</title>
    <para>
      Most software synthetisers don't provide *any* king of synchronisation.
      It seems neraly impossible to integrate such programs into Speech Deamon
      because synchronisation is one of the most important things there.
    </para>
  </sect1>
  
</chapter>
